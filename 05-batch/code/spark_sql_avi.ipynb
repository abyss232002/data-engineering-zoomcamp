{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/abyssde232024/spark/spark-3.3.2-bin-hadoop3/python/pyspark/__init__.py'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pyspark.__file__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(SparkSession.getActiveSession())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/04/05 16:07:15 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark_sql = SparkSession.builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .appName('dezoomcamp2024') \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_green = spark_sql.read.parquet('data/processed/green/*/*', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+---------------------+------------------+----------+------------+------------+---------------+-------------+-----------+-----+-------+----------+------------+---------+---------------------+------------+------------+---------+--------------------+\n",
      "|VendorID|lpep_pickup_datetime|lpep_dropoff_datetime|store_and_fwd_flag|RatecodeID|PULocationID|DOLocationID|passenger_count|trip_distance|fare_amount|extra|mta_tax|tip_amount|tolls_amount|ehail_fee|improvement_surcharge|total_amount|payment_type|trip_type|congestion_surcharge|\n",
      "+--------+--------------------+---------------------+------------------+----------+------------+------------+---------------+-------------+-----------+-----+-------+----------+------------+---------+---------------------+------------+------------+---------+--------------------+\n",
      "|       2| 2020-01-26 12:45:44|  2020-01-26 12:45:45|                 N|         5|          25|         264|              1|          .00|      40.05|    0|      0|      8.07|           0|     null|                  0.3|       48.42|           1|        2|                   0|\n",
      "|    null| 2020-01-17 15:59:00|  2020-01-17 16:44:00|              null|      null|          71|          55|           null|         8.87|      26.86| 2.75|    0.5|         0|           0|     null|                    0|       30.11|        null|     null|                null|\n",
      "|       2| 2020-01-17 17:56:45|  2020-01-17 18:19:27|                 N|         1|          41|         244|              1|         3.48|       16.5|    1|    0.5|      3.66|           0|     null|                  0.3|       21.96|           1|        1|                   0|\n",
      "|       2| 2020-01-20 20:39:15|  2020-01-20 20:42:44|                 N|         1|          43|         151|              1|          .88|          5|  0.5|    0.5|         1|           0|     null|                  0.3|         7.3|           1|        1|                   0|\n",
      "|       2| 2020-01-16 22:04:55|  2020-01-16 22:17:36|                 N|         1|           7|         129|              1|         1.91|         10|  0.5|    0.5|      2.26|           0|     null|                  0.3|       13.56|           1|        1|                   0|\n",
      "+--------+--------------------+---------------------+------------------+----------+------------+------------+---------------+-------------+-----------+-----+-------+----------+------------+---------+---------------------+------------+------------+---------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_green.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- VendorID: string (nullable = true)\n",
      " |-- lpep_pickup_datetime: timestamp (nullable = true)\n",
      " |-- lpep_dropoff_datetime: timestamp (nullable = true)\n",
      " |-- store_and_fwd_flag: string (nullable = true)\n",
      " |-- RatecodeID: integer (nullable = true)\n",
      " |-- PULocationID: integer (nullable = true)\n",
      " |-- DOLocationID: integer (nullable = true)\n",
      " |-- passenger_count: integer (nullable = true)\n",
      " |-- trip_distance: string (nullable = true)\n",
      " |-- fare_amount: string (nullable = true)\n",
      " |-- extra: string (nullable = true)\n",
      " |-- mta_tax: string (nullable = true)\n",
      " |-- tip_amount: string (nullable = true)\n",
      " |-- tolls_amount: string (nullable = true)\n",
      " |-- ehail_fee: string (nullable = true)\n",
      " |-- improvement_surcharge: string (nullable = true)\n",
      " |-- total_amount: string (nullable = true)\n",
      " |-- payment_type: integer (nullable = true)\n",
      " |-- trip_type: integer (nullable = true)\n",
      " |-- congestion_surcharge: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_green.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_yellow = spark_sql.read.parquet('data/processed/yellow/*/*', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+\n",
      "|VendorID|tpep_pickup_datetime|tpep_dropoff_datetime|passenger_count|trip_distance|RatecodeID|store_and_fwd_flag|PULocationID|DOLocationID|payment_type|fare_amount|extra|mta_tax|tip_amount|tolls_amount|improvement_surcharge|total_amount|congestion_surcharge|\n",
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+\n",
      "|       2| 2020-01-06 09:18:38|  2020-01-06 09:33:56|              1|         3.03|         1|                 N|         263|         233|           1|       12.0|  0.0|    0.5|       1.5|         0.0|                  0.3|        16.8|                 2.5|\n",
      "|       2| 2020-01-08 18:55:19|  2020-01-08 18:58:38|              1|          0.4|         1|                 N|         234|         107|           1|        4.0|  1.0|    0.5|      1.66|         0.0|                  0.3|        9.96|                 2.5|\n",
      "|       2| 2020-01-16 12:11:53|  2020-01-16 12:42:44|              1|         2.46|         1|                 N|          68|         229|           1|       19.0|  0.0|    0.5|      4.46|         0.0|                  0.3|       26.76|                 2.5|\n",
      "|       2| 2020-01-11 01:55:59|  2020-01-11 02:03:21|              6|          1.9|         1|                 N|         230|          90|           1|        8.0|  0.5|    0.5|      2.36|         0.0|                  0.3|       14.16|                 2.5|\n",
      "|       2| 2020-01-01 21:31:48|  2020-01-01 21:36:01|              1|         0.77|         1|                 N|         238|         239|           1|        5.0|  0.5|    0.5|      1.76|         0.0|                  0.3|       10.56|                 2.5|\n",
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_yellow.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- VendorID: integer (nullable = true)\n",
      " |-- tpep_pickup_datetime: timestamp (nullable = true)\n",
      " |-- tpep_dropoff_datetime: timestamp (nullable = true)\n",
      " |-- passenger_count: integer (nullable = true)\n",
      " |-- trip_distance: double (nullable = true)\n",
      " |-- RatecodeID: integer (nullable = true)\n",
      " |-- store_and_fwd_flag: string (nullable = true)\n",
      " |-- PULocationID: integer (nullable = true)\n",
      " |-- DOLocationID: integer (nullable = true)\n",
      " |-- payment_type: integer (nullable = true)\n",
      " |-- fare_amount: double (nullable = true)\n",
      " |-- extra: double (nullable = true)\n",
      " |-- mta_tax: double (nullable = true)\n",
      " |-- tip_amount: double (nullable = true)\n",
      " |-- tolls_amount: double (nullable = true)\n",
      " |-- improvement_surcharge: double (nullable = true)\n",
      " |-- total_amount: double (nullable = true)\n",
      " |-- congestion_surcharge: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_yellow.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['VendorID',\n",
       " 'lpep_pickup_datetime',\n",
       " 'lpep_dropoff_datetime',\n",
       " 'store_and_fwd_flag',\n",
       " 'RatecodeID',\n",
       " 'PULocationID',\n",
       " 'DOLocationID',\n",
       " 'passenger_count',\n",
       " 'trip_distance',\n",
       " 'fare_amount',\n",
       " 'extra',\n",
       " 'mta_tax',\n",
       " 'tip_amount',\n",
       " 'tolls_amount',\n",
       " 'ehail_fee',\n",
       " 'improvement_surcharge',\n",
       " 'total_amount',\n",
       " 'payment_type',\n",
       " 'trip_type',\n",
       " 'congestion_surcharge']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_green.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['VendorID',\n",
       " 'tpep_pickup_datetime',\n",
       " 'tpep_dropoff_datetime',\n",
       " 'passenger_count',\n",
       " 'trip_distance',\n",
       " 'RatecodeID',\n",
       " 'store_and_fwd_flag',\n",
       " 'PULocationID',\n",
       " 'DOLocationID',\n",
       " 'payment_type',\n",
       " 'fare_amount',\n",
       " 'extra',\n",
       " 'mta_tax',\n",
       " 'tip_amount',\n",
       " 'tolls_amount',\n",
       " 'improvement_surcharge',\n",
       " 'total_amount',\n",
       " 'congestion_surcharge']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_yellow.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "set instruction is to check intersection of values between two set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ehail_fee', 'lpep_dropoff_datetime', 'lpep_pickup_datetime', 'trip_type'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(df_green.columns) - set(df_yellow.columns)  # {'ehail_fee', 'trip_type', 'total_amount'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tpep_dropoff_datetime', 'tpep_pickup_datetime'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(df_yellow.columns) - set(df_green.columns)  # {'store_and_fwd_flag', 'rate_code', 'fare_amount'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rename dataframe column names to essentially having same name in both df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_yellow = df_yellow \\\n",
    "            .withColumnRenamed('tpep_dropoff_datetime', 'dropoff_datetime') \\\n",
    "            .withColumnRenamed('tpep_pickup_datetime', 'pickup_datetime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_green = df_green \\\n",
    "            .withColumnRenamed('lpep_dropoff_datetime', 'dropoff_datetime') \\\n",
    "            .withColumnRenamed('lpep_pickup_datetime', 'pickup_datetime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['VendorID',\n",
       " 'pickup_datetime',\n",
       " 'dropoff_datetime',\n",
       " 'store_and_fwd_flag',\n",
       " 'RatecodeID',\n",
       " 'PULocationID',\n",
       " 'DOLocationID',\n",
       " 'passenger_count',\n",
       " 'trip_distance',\n",
       " 'fare_amount',\n",
       " 'extra',\n",
       " 'mta_tax',\n",
       " 'tip_amount',\n",
       " 'tolls_amount',\n",
       " 'ehail_fee',\n",
       " 'improvement_surcharge',\n",
       " 'total_amount',\n",
       " 'payment_type',\n",
       " 'trip_type',\n",
       " 'congestion_surcharge']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_green.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['VendorID',\n",
       " 'pickup_datetime',\n",
       " 'dropoff_datetime',\n",
       " 'passenger_count',\n",
       " 'trip_distance',\n",
       " 'RatecodeID',\n",
       " 'store_and_fwd_flag',\n",
       " 'PULocationID',\n",
       " 'DOLocationID',\n",
       " 'payment_type',\n",
       " 'fare_amount',\n",
       " 'extra',\n",
       " 'mta_tax',\n",
       " 'tip_amount',\n",
       " 'tolls_amount',\n",
       " 'improvement_surcharge',\n",
       " 'total_amount',\n",
       " 'congestion_surcharge']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_yellow.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recreate the columns in the yellow taxi data so that it has the same columns as the green taxi data. Fill in the missing columns with null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  create a common column list which is present in both green and yellow dataframes and order them same as green dataframe\n",
    "common_columns = []\n",
    "yellow_columns = df_yellow.columns\n",
    "for column in df_green.columns:\n",
    "    if column in yellow_columns:\n",
    "        common_columns.append(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['VendorID',\n",
       " 'pickup_datetime',\n",
       " 'dropoff_datetime',\n",
       " 'store_and_fwd_flag',\n",
       " 'RatecodeID',\n",
       " 'PULocationID',\n",
       " 'DOLocationID',\n",
       " 'passenger_count',\n",
       " 'trip_distance',\n",
       " 'fare_amount',\n",
       " 'extra',\n",
       " 'mta_tax',\n",
       " 'tip_amount',\n",
       " 'tolls_amount',\n",
       " 'improvement_surcharge',\n",
       " 'total_amount',\n",
       " 'payment_type',\n",
       " 'congestion_surcharge']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------+-------------------+------------------+----------+------------+------------+---------------+-------------+-----------+-----+-------+----------+------------+---------------------+------------+------------+--------------------+\n",
      "|VendorID|    pickup_datetime|   dropoff_datetime|store_and_fwd_flag|RatecodeID|PULocationID|DOLocationID|passenger_count|trip_distance|fare_amount|extra|mta_tax|tip_amount|tolls_amount|improvement_surcharge|total_amount|payment_type|congestion_surcharge|\n",
      "+--------+-------------------+-------------------+------------------+----------+------------+------------+---------------+-------------+-----------+-----+-------+----------+------------+---------------------+------------+------------+--------------------+\n",
      "|       2|2020-01-26 12:45:44|2020-01-26 12:45:45|                 N|         5|          25|         264|              1|          .00|      40.05|    0|      0|      8.07|           0|                  0.3|       48.42|           1|                   0|\n",
      "|    null|2020-01-17 15:59:00|2020-01-17 16:44:00|              null|      null|          71|          55|           null|         8.87|      26.86| 2.75|    0.5|         0|           0|                    0|       30.11|        null|                null|\n",
      "|       2|2020-01-17 17:56:45|2020-01-17 18:19:27|                 N|         1|          41|         244|              1|         3.48|       16.5|    1|    0.5|      3.66|           0|                  0.3|       21.96|           1|                   0|\n",
      "|       2|2020-01-20 20:39:15|2020-01-20 20:42:44|                 N|         1|          43|         151|              1|          .88|          5|  0.5|    0.5|         1|           0|                  0.3|         7.3|           1|                   0|\n",
      "|       2|2020-01-16 22:04:55|2020-01-16 22:17:36|                 N|         1|           7|         129|              1|         1.91|         10|  0.5|    0.5|      2.26|           0|                  0.3|       13.56|           1|                   0|\n",
      "+--------+-------------------+-------------------+------------------+----------+------------+------------+---------------+-------------+-----------+-----+-------+----------+------------+---------------------+------------+------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_green.select(common_columns).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add service type column to green dataframe and yellow dataframe\n",
    "from pyspark.sql import functions as F\n",
    "df_green = df_green.withColumn('service_type', F.lit('green'))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_yellow = df_yellow.withColumn('service_type', F.lit('yellow'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------+-------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+------------+\n",
      "|VendorID|    pickup_datetime|   dropoff_datetime|passenger_count|trip_distance|RatecodeID|store_and_fwd_flag|PULocationID|DOLocationID|payment_type|fare_amount|extra|mta_tax|tip_amount|tolls_amount|improvement_surcharge|total_amount|congestion_surcharge|service_type|\n",
      "+--------+-------------------+-------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+------------+\n",
      "|       2|2020-01-06 09:18:38|2020-01-06 09:33:56|              1|         3.03|         1|                 N|         263|         233|           1|       12.0|  0.0|    0.5|       1.5|         0.0|                  0.3|        16.8|                 2.5|      yellow|\n",
      "|       2|2020-01-08 18:55:19|2020-01-08 18:58:38|              1|          0.4|         1|                 N|         234|         107|           1|        4.0|  1.0|    0.5|      1.66|         0.0|                  0.3|        9.96|                 2.5|      yellow|\n",
      "|       2|2020-01-16 12:11:53|2020-01-16 12:42:44|              1|         2.46|         1|                 N|          68|         229|           1|       19.0|  0.0|    0.5|      4.46|         0.0|                  0.3|       26.76|                 2.5|      yellow|\n",
      "|       2|2020-01-11 01:55:59|2020-01-11 02:03:21|              6|          1.9|         1|                 N|         230|          90|           1|        8.0|  0.5|    0.5|      2.36|         0.0|                  0.3|       14.16|                 2.5|      yellow|\n",
      "|       2|2020-01-01 21:31:48|2020-01-01 21:36:01|              1|         0.77|         1|                 N|         238|         239|           1|        5.0|  0.5|    0.5|      1.76|         0.0|                  0.3|       10.56|                 2.5|      yellow|\n",
      "+--------+-------------------+-------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_yellow.show(5)\n",
    "df_yellow_select = df_yellow.select(common_columns + ['service_type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------+-------------------+------------------+----------+------------+------------+---------------+-------------+-----------+-----+-------+----------+------------+---------+---------------------+------------+------------+---------+--------------------+------------+\n",
      "|VendorID|    pickup_datetime|   dropoff_datetime|store_and_fwd_flag|RatecodeID|PULocationID|DOLocationID|passenger_count|trip_distance|fare_amount|extra|mta_tax|tip_amount|tolls_amount|ehail_fee|improvement_surcharge|total_amount|payment_type|trip_type|congestion_surcharge|service_type|\n",
      "+--------+-------------------+-------------------+------------------+----------+------------+------------+---------------+-------------+-----------+-----+-------+----------+------------+---------+---------------------+------------+------------+---------+--------------------+------------+\n",
      "|       2|2020-01-26 12:45:44|2020-01-26 12:45:45|                 N|         5|          25|         264|              1|          .00|      40.05|    0|      0|      8.07|           0|     null|                  0.3|       48.42|           1|        2|                   0|       green|\n",
      "|    null|2020-01-17 15:59:00|2020-01-17 16:44:00|              null|      null|          71|          55|           null|         8.87|      26.86| 2.75|    0.5|         0|           0|     null|                    0|       30.11|        null|     null|                null|       green|\n",
      "|       2|2020-01-17 17:56:45|2020-01-17 18:19:27|                 N|         1|          41|         244|              1|         3.48|       16.5|    1|    0.5|      3.66|           0|     null|                  0.3|       21.96|           1|        1|                   0|       green|\n",
      "|       2|2020-01-20 20:39:15|2020-01-20 20:42:44|                 N|         1|          43|         151|              1|          .88|          5|  0.5|    0.5|         1|           0|     null|                  0.3|         7.3|           1|        1|                   0|       green|\n",
      "|       2|2020-01-16 22:04:55|2020-01-16 22:17:36|                 N|         1|           7|         129|              1|         1.91|         10|  0.5|    0.5|      2.26|           0|     null|                  0.3|       13.56|           1|        1|                   0|       green|\n",
      "+--------+-------------------+-------------------+------------------+----------+------------+------------+---------------+-------------+-----------+-----+-------+----------+------------+---------+---------------------+------------+------------+---------+--------------------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_green.show(5)\n",
    "df_green_select = df_green.select(common_columns + ['service_type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# union both green and yellow dataframes\n",
    "df_trip_data = df_green_select.unionAll(df_yellow_select)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 14:====================================================>   (15 + 1) / 16]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------+\n",
      "|service_type|   count|\n",
      "+------------+--------+\n",
      "|       green| 2304517|\n",
      "|      yellow|39649199|\n",
      "+------------+--------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# run group by on the dataframe to get the count of each service type\n",
    "df_trip_data.groupBy('service_type').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abyssde232024/spark/spark-3.3.2-bin-hadoop3/python/pyspark/sql/dataframe.py:229: FutureWarning: Deprecated in 2.0, use createOrReplaceTempView instead.\n",
      "  warnings.warn(\"Deprecated in 2.0, use createOrReplaceTempView instead.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# create temporary table from the dataframe\n",
    "df_trip_data.registerTempTable('trip_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 17:=============================================>          (13 + 3) / 16]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------+\n",
      "|service_type|   count|\n",
      "+------------+--------+\n",
      "|       green| 2304517|\n",
      "|      yellow|39649199|\n",
      "+------------+--------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# use spark sql to get the count of each service type\n",
    "spark_sql.sql('select service_type, count(1) as count from trip_data group by service_type').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result = spark_sql.sql('''\n",
    "select \n",
    "    -- Reveneue grouping \n",
    "    PULocationID as revenue_zone,\n",
    "    date_trunc(\"month\", \"pickup_datetime\") as revenue_month, \n",
    "    service_type, \n",
    "\n",
    "    -- Revenue calculation \n",
    "    sum(fare_amount) as revenue_monthly_fare,\n",
    "    sum(extra) as revenue_monthly_extra,\n",
    "    sum(mta_tax) as revenue_monthly_mta_tax,\n",
    "    sum(tip_amount) as revenue_monthly_tip_amount,\n",
    "    sum(tolls_amount) as revenue_monthly_tolls_amount,\n",
    "    sum(improvement_surcharge) as revenue_monthly_improvement_surcharge,\n",
    "    sum(total_amount) as revenue_monthly_total_amount,\n",
    "\n",
    "    -- Additional calculations\n",
    "    avg(passenger_count) as avg_monthly_passenger_count,\n",
    "    avg(trip_distance) as avg_monthly_trip_distance\n",
    "\n",
    "from trip_data\n",
    "group by 1,2,3\n",
    "''')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- revenue_zone: integer (nullable = true)\n",
      " |-- revenue_month: timestamp (nullable = true)\n",
      " |-- service_type: string (nullable = false)\n",
      " |-- revenue_monthly_fare: double (nullable = true)\n",
      " |-- revenue_monthly_extra: double (nullable = true)\n",
      " |-- revenue_monthly_mta_tax: double (nullable = true)\n",
      " |-- revenue_monthly_tip_amount: double (nullable = true)\n",
      " |-- revenue_monthly_tolls_amount: double (nullable = true)\n",
      " |-- revenue_monthly_improvement_surcharge: double (nullable = true)\n",
      " |-- revenue_monthly_total_amount: double (nullable = true)\n",
      " |-- avg_monthly_passenger_count: double (nullable = true)\n",
      " |-- avg_monthly_trip_distance: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_result.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 32:====================================================>   (15 + 1) / 16]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-------------+------------+--------------------+---------------------+-----------------------+--------------------------+----------------------------+-------------------------------------+----------------------------+---------------------------+-------------------------+\n",
      "|revenue_zone|revenue_month|service_type|revenue_monthly_fare|revenue_monthly_extra|revenue_monthly_mta_tax|revenue_monthly_tip_amount|revenue_monthly_tolls_amount|revenue_monthly_improvement_surcharge|revenue_monthly_total_amount|avg_monthly_passenger_count|avg_monthly_trip_distance|\n",
      "+------------+-------------+------------+--------------------+---------------------+-----------------------+--------------------------+----------------------------+-------------------------------------+----------------------------+---------------------------+-------------------------+\n",
      "|         254|         null|       green|   278150.7099999999|   11320.519999999999|                  854.5|         9569.900000000001|           13415.77999999989|                   2786.0999999999367|           316342.1100000009|          1.138095238095238|       249.57145962406813|\n",
      "|          38|         null|       green|    82767.6100000003|               2537.6|                  237.5|        2433.5299999999997|          3530.9100000000017|                    664.2000000000029|           92221.80000000012|         1.1342925659472423|       151.58323426573423|\n",
      "|         229|         null|       green|            13658.47|                689.3|                   23.0|                    388.43|           789.1000000000003|                   131.99999999999994|                    15699.05|         1.2222222222222223|         8.25965986394558|\n",
      "|         188|         null|       green|   430873.5499999911|   21162.420000000002|                 1931.0|                  19095.49|           6813.589999999965|                    5714.399999999499|          486764.00000000105|         1.1596080910240203|        82.27654449456634|\n",
      "|         232|         null|       green|   40609.98000000003|   1913.9500000000003|                  64.55|                    1314.6|          1395.4100000000008|                   403.49999999999983|                    45729.54|          1.069767441860465|        261.1684855233854|\n",
      "+------------+-------------+------------+--------------------+---------------------+-----------------------+--------------------------+----------------------------+-------------------------------------+----------------------------+---------------------------+-------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_result.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_result.repartition(4).write.parquet('data/report/revenue', mode='overwrite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_result.write.parquet('data/report/revenue', mode='overwrite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Home work question 4\n",
    "df_hw = spark_sql.read.parquet('fhvhv/2019/10/', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+-------------------+------------+------------+-------+----------------------+\n",
      "|dispatching_base_num|    pickup_datetime|   dropOff_datetime|PUlocationID|DOlocationID|SR_Flag|Affiliated_base_number|\n",
      "+--------------------+-------------------+-------------------+------------+------------+-------+----------------------+\n",
      "|              B02784|2019-10-01 09:55:38|2019-10-01 10:05:43|          89|          85|   null|                  null|\n",
      "|              B01233|2019-10-08 00:09:01|2019-10-08 00:11:14|         264|          81|   null|                B01233|\n",
      "|              B02688|2019-10-02 10:59:00|2019-10-02 11:34:46|         264|         107|   null|                B02688|\n",
      "|              B01285|2019-10-03 21:56:10|2019-10-03 22:22:18|         264|         235|   null|                B01285|\n",
      "|              B00706|2019-10-05 02:48:13|2019-10-05 02:56:36|         115|         245|   null|                B00706|\n",
      "+--------------------+-------------------+-------------------+------------+------------+-------+----------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_hw.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as fn\n",
    "df_hw = df_hw \\\n",
    ".withColumn(\"tripDuration\", fn.round(((df_hw.dropOff_datetime.cast(\"long\") - df_hw.pickup_datetime.cast(\"long\")) / 3600), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+-------------------+------------+------------+-------+----------------------+------------+\n",
      "|dispatching_base_num|    pickup_datetime|   dropOff_datetime|PUlocationID|DOlocationID|SR_Flag|Affiliated_base_number|tripDuration|\n",
      "+--------------------+-------------------+-------------------+------------+------------+-------+----------------------+------------+\n",
      "|              B02784|2019-10-01 09:55:38|2019-10-01 10:05:43|          89|          85|   null|                  null|        0.17|\n",
      "|              B01233|2019-10-08 00:09:01|2019-10-08 00:11:14|         264|          81|   null|                B01233|        0.04|\n",
      "|              B02688|2019-10-02 10:59:00|2019-10-02 11:34:46|         264|         107|   null|                B02688|         0.6|\n",
      "|              B01285|2019-10-03 21:56:10|2019-10-03 22:22:18|         264|         235|   null|                B01285|        0.44|\n",
      "|              B00706|2019-10-05 02:48:13|2019-10-05 02:56:36|         115|         245|   null|                B00706|        0.14|\n",
      "+--------------------+-------------------+-------------------+------------+------------+-------+----------------------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_hw.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abyssde232024/spark/spark-3.3.2-bin-hadoop3/python/pyspark/sql/dataframe.py:229: FutureWarning: Deprecated in 2.0, use createOrReplaceTempView instead.\n",
      "  warnings.warn(\"Deprecated in 2.0, use createOrReplaceTempView instead.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# create temporary table from the dataframe\n",
    "df_hw.registerTempTable('fhvhv_trip_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+-------------------+------------+------------+-------+----------------------+------------+\n",
      "|dispatching_base_num|    pickup_datetime|   dropOff_datetime|PUlocationID|DOlocationID|SR_Flag|Affiliated_base_number|tripDuration|\n",
      "+--------------------+-------------------+-------------------+------------+------------+-------+----------------------+------------+\n",
      "|              B02784|2019-10-01 09:55:38|2019-10-01 10:05:43|          89|          85|   null|                  null|        0.17|\n",
      "|              B01233|2019-10-08 00:09:01|2019-10-08 00:11:14|         264|          81|   null|                B01233|        0.04|\n",
      "|              B02688|2019-10-02 10:59:00|2019-10-02 11:34:46|         264|         107|   null|                B02688|         0.6|\n",
      "|              B01285|2019-10-03 21:56:10|2019-10-03 22:22:18|         264|         235|   null|                B01285|        0.44|\n",
      "|              B00706|2019-10-05 02:48:13|2019-10-05 02:56:36|         115|         245|   null|                B00706|        0.14|\n",
      "+--------------------+-------------------+-------------------+------------+------------+-------+----------------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark_sql.sql('''\n",
    "              select * from fhvhv_trip_data limit 5\n",
    "              ''').show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+-------------------+------------+------------+-------+----------------------+------------+\n",
      "|dispatching_base_num|    pickup_datetime|   dropOff_datetime|PUlocationID|DOlocationID|SR_Flag|Affiliated_base_number|tripDuration|\n",
      "+--------------------+-------------------+-------------------+------------+------------+-------+----------------------+------------+\n",
      "|              B02832|2019-10-11 18:00:00|2091-10-11 18:30:00|         264|         264|   null|                B02832|    631152.5|\n",
      "|              B02832|2019-10-28 09:00:00|2091-10-28 09:30:00|         264|         264|   null|                B02832|    631152.5|\n",
      "+--------------------+-------------------+-------------------+------------+------------+-------+----------------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark_sql.sql('''\n",
    "              select * \n",
    "                from fhvhv_trip_data\n",
    "                where tripDuration = (select max(tripDuration) from fhvhv_trip_data)\n",
    "              ''').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-04-05 16:32:12--  https://github.com/DataTalksClub/nyc-tlc-data/releases/download/misc/taxi_zone_lookup.csv\n",
      "Resolving github.com (github.com)... 140.82.114.4\n",
      "Connecting to github.com (github.com)|140.82.114.4|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/513814948/5a2cc2f5-b4cd-4584-9c62-a6ea97ed0e6a?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVCODYLSA53PQK4ZA%2F20240405%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240405T163212Z&X-Amz-Expires=300&X-Amz-Signature=1ee48d6772f3c6b5988e6bf4969be0e26eaa6c7e3dce9a926fec8036160f7c60&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=513814948&response-content-disposition=attachment%3B%20filename%3Dtaxi_zone_lookup.csv&response-content-type=application%2Foctet-stream [following]\n",
      "--2024-04-05 16:32:12--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/513814948/5a2cc2f5-b4cd-4584-9c62-a6ea97ed0e6a?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVCODYLSA53PQK4ZA%2F20240405%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240405T163212Z&X-Amz-Expires=300&X-Amz-Signature=1ee48d6772f3c6b5988e6bf4969be0e26eaa6c7e3dce9a926fec8036160f7c60&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=513814948&response-content-disposition=attachment%3B%20filename%3Dtaxi_zone_lookup.csv&response-content-type=application%2Foctet-stream\n",
      "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
      "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 12322 (12K) [application/octet-stream]\n",
      "Saving to: ‘taxi_zone_lookup.csv’\n",
      "\n",
      "taxi_zone_lookup.cs 100%[===================>]  12.03K  --.-KB/s    in 0s      \n",
      "\n",
      "2024-04-05 16:32:12 (55.4 MB/s) - ‘taxi_zone_lookup.csv’ saved [12322/12322]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget 'https://github.com/DataTalksClub/nyc-tlc-data/releases/download/misc/taxi_zone_lookup.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_lookup = pd.read_csv('taxi_zone_lookup.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LocationID       int64\n",
       "Borough         object\n",
       "Zone            object\n",
       "service_zone    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lookup.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lookup = spark_sql.read \\\n",
    "            .option(\"header\", \"true\") \\\n",
    "            .csv('taxi_zone_lookup.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- LocationID: string (nullable = true)\n",
      " |-- Borough: string (nullable = true)\n",
      " |-- Zone: string (nullable = true)\n",
      " |-- service_zone: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_lookup.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- dispatching_base_num: string (nullable = true)\n",
      " |-- pickup_datetime: timestamp (nullable = true)\n",
      " |-- dropOff_datetime: timestamp (nullable = true)\n",
      " |-- PUlocationID: integer (nullable = true)\n",
      " |-- DOlocationID: integer (nullable = true)\n",
      " |-- SR_Flag: string (nullable = true)\n",
      " |-- Affiliated_base_number: string (nullable = true)\n",
      " |-- tripDuration: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_hw.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, StringType, TimestampType, LongType, DoubleType, IntegerType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "lookup_schema = StructType([\n",
    "    StructField(\"LocationID\", IntegerType(), nullable=True),\n",
    "    StructField(\"Borough\", StringType(), nullable=True),\n",
    "    StructField(\"Zone\", StringType(), nullable=True),\n",
    "    StructField(\"service_zone\", StringType(), nullable=True)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lookup = spark_sql.read \\\n",
    "            .option(\"header\", \"true\") \\\n",
    "            .schema(lookup_schema) \\\n",
    "            .csv('taxi_zone_lookup.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "df_hw_q6 = df_hw \\\n",
    "    .join(df_lookup, col('PULocationID') == col('LocationID'), 'left') \\\n",
    "    .drop('LocationID') \\\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+-------------------+------------+------------+-------+----------------------+------------+-------------+--------------------+------------+\n",
      "|dispatching_base_num|    pickup_datetime|   dropOff_datetime|PUlocationID|DOlocationID|SR_Flag|Affiliated_base_number|tripDuration|      Borough|                Zone|service_zone|\n",
      "+--------------------+-------------------+-------------------+------------+------------+-------+----------------------+------------+-------------+--------------------+------------+\n",
      "|              B02784|2019-10-01 09:55:38|2019-10-01 10:05:43|          89|          85|   null|                  null|        0.17|     Brooklyn|Flatbush/Ditmas Park|   Boro Zone|\n",
      "|              B01233|2019-10-08 00:09:01|2019-10-08 00:11:14|         264|          81|   null|                B01233|        0.04|      Unknown|                  NV|         N/A|\n",
      "|              B02688|2019-10-02 10:59:00|2019-10-02 11:34:46|         264|         107|   null|                B02688|         0.6|      Unknown|                  NV|         N/A|\n",
      "|              B01285|2019-10-03 21:56:10|2019-10-03 22:22:18|         264|         235|   null|                B01285|        0.44|      Unknown|                  NV|         N/A|\n",
      "|              B00706|2019-10-05 02:48:13|2019-10-05 02:56:36|         115|         245|   null|                B00706|        0.14|Staten Island| Grymes Hill/Clifton|   Boro Zone|\n",
      "+--------------------+-------------------+-------------------+------------+------------+-------+----------------------+------------+-------------+--------------------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_hw_q6.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abyssde232024/spark/spark-3.3.2-bin-hadoop3/python/pyspark/sql/dataframe.py:229: FutureWarning: Deprecated in 2.0, use createOrReplaceTempView instead.\n",
      "  warnings.warn(\"Deprecated in 2.0, use createOrReplaceTempView instead.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "df_hw_q6.registerTempTable('fhvhv__final_trip_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+\n",
      "|cnt|                zone|\n",
      "+---+--------------------+\n",
      "|  1|         Jamaica Bay|\n",
      "|  2|Governor's Island...|\n",
      "|  5| Green-Wood Cemetery|\n",
      "|  8|       Broad Channel|\n",
      "| 14|     Highbridge Park|\n",
      "| 15|        Battery Park|\n",
      "| 23|Saint Michaels Ce...|\n",
      "| 25|Breezy Point/Fort...|\n",
      "| 26|Marine Park/Floyd...|\n",
      "| 29|        Astoria Park|\n",
      "| 39|    Inwood Hill Park|\n",
      "| 47|       Willets Point|\n",
      "| 53|Forest Park/Highl...|\n",
      "| 57|  Brooklyn Navy Yard|\n",
      "| 62|        Crotona Park|\n",
      "| 77|        Country Club|\n",
      "| 89|     Freshkills Park|\n",
      "| 98|       Prospect Park|\n",
      "|105|     Columbia Street|\n",
      "|110|  South Williamsburg|\n",
      "+---+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Homework question number 6\n",
    "spark_sql.sql('''\n",
    "              select count(1) as cnt,zone\n",
    "              from fhvhv__final_trip_data\n",
    "              group by zone\n",
    "              order by cnt asc ''').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_sql.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
